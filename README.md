# Biomedical Summarization Using Graph-Augmented Retrieval-Augmented Generation (GraphRAG)

This repository implements a biomedical summarization pipeline using fine-tuned `mT5` models and a Graph-Augmented Retrieval-Augmented Generation (GraphRAG) component. The system is designed to summarize clinical case reports with improved factuality by leveraging entity-relation graphs constructed from the text.

## Overview

The project uses:

- **mT5-small** as the base model for multilingual biomedical summarization
- **Custom tokenizer and dataset preprocessing**
- **Trigram repetition penalty** during fine-tuning to improve ROUGE-2 scores
- **Neo4j + NetworkX** for knowledge graph construction and visualization
- **Graph-based summaries** generated by traversing high-connectivity subgraphs

## Project Structure

```
.
â”œâ”€â”€ clean_mt5_tokenizer/             # Custom tokenizer files
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ converted_json/              # Parsed JSON case reports
â”‚   â”œâ”€â”€ converted_json_finetune_text/
â”‚   â”œâ”€â”€ finetune_data/               # Inputs for training the fine-tuned mT5 model
â”‚   â”œâ”€â”€ training_data/               # Original training texts
â”‚   â””â”€â”€ data.tar.gz                  # Compressed dataset archive
â”‚
â”œâ”€â”€ final_model/                     # Final fine-tuned mT5 model
â”œâ”€â”€ fixed_mt5_model/                 # Cleaned or preprocessed mT5 checkpoint
â”œâ”€â”€ graph/                           # Graph construction utilities
â”œâ”€â”€ inference/                       # Scripts for inference and generation
â”œâ”€â”€ neo4j/import/                    # CSV files for Neo4j visualization
â”‚   â”œâ”€â”€ entities.csv
â”‚   â””â”€â”€ relationships.csv
â”‚
â”œâ”€â”€ preprocessing/                   # Data preprocessing and tokenization
â”‚   â”œâ”€â”€ conversion_script.py
â”‚   â””â”€â”€ tokenization.py
â”‚
â”œâ”€â”€ tokenized_dataset/              # HuggingFace-style tokenized Arrow dataset
â”œâ”€â”€ tokenized_large_dataset/        # (Optional) For full-scale fine-tuning
â”œâ”€â”€ training/                        # Training scripts and utilities
â”‚   â”œâ”€â”€ training_mt5.py
â”‚   â””â”€â”€ install_dependencies.py
â”œâ”€â”€ README.md                        # This documentation
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ .gitignore
```

## Dataset

- Based on **MultiClinSum** or similar biomedical case reports, https://zenodo.org/records/15535720
- Preprocessed using `conversion_script.py` and `tokenization.py`
- Stored in HuggingFace Arrow format (`tokenized_dataset/`)

## Model Architecture

- **Backbone**: `google/mt5-small`
- **Loss**:
  - Standard cross-entropy
  - Trigram repetition penalty to improve ROUGE-2
  - Label smoothing (0.1)
- **Trainer**: HuggingFace `Seq2SeqTrainer`
- **Regularization**: Gradient checkpointing, accumulation steps

## Training

To train the model:

```bash
python training_MT5.py
```

This script:
- Loads a custom tokenizer
- Fine-tunes `mT5` on the biomedical dataset
- Applies trigram repetition penalty
- Logs to TensorBoard and saves checkpoints

## Inference

To generate summaries from the fine-tuned model:

```bash
python inference/generate_text.py
```

You can:
- Generate for the full test dataset
- Slice for first 10â€“15 examples during debugging
- Output predictions to a `.txt` file

## Graph-Augmented Retrieval (GraphRAG)

### Neo4j + NetworkX

Graphs are constructed from extracted biomedical entities and relations:
- Use `entities.csv` and `relationships.csv` with Neo4j for visualization
- Use `graph/` scripts to compute communities and augment summaries

### Example:

```bash
python graph/graph_summarizer.py --input predictions.txt
```

Outputs:
- Community-specific summaries
- Evaluated with ROUGE metrics

## Evaluation

Evaluation is performed using ROUGE:

```python
evaluate.load("rouge").compute(predictions=preds, references=labels)
```

Metrics include:
- ROUGE-1
- ROUGE-2 (focus)
- ROUGE-L

Custom cleaning is applied to strip `<extra_id_x>` tokens and repeated bigrams.

## Dependencies

Install via:

```bash
pip install -r requirements.txt
```

Main libraries:
- `transformers`
- `datasets`
- `evaluate`
- `torch`
- `networkx`
- `neo4j`
- `sentencepiece`

## Results 

- Fine-tuned `mT5` with trigram penalty improves ROUGE-2 marginally
- Graph summaries show promise for long documents with high redundancy
- Neo4j integration helps visualize concept clusters

## Future Work

- Add graph-based filtering during generation
- Integrate biomedical ontologies (UMLS, MeSH)
- Improve GraphRAG using GNNs for node scoring

## ðŸ§  Acknowledgements

- [MultiClinSum Dataset (Zenodo)](https://zenodo.org/record/...)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [Neo4j Community](https://community.neo4j.com/)
